
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Utilities &#8212; ANTsPyNet 0.0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Architectures" href="architectures.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="utilities">
<h1>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h1>
<div class="section" id="custom-metrics">
<h2>Custom metrics<a class="headerlink" href="#custom-metrics" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="antspynet.utilities.binary_dice_coefficient">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">binary_dice_coefficient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">smoothing_factor</span><span class="o">=</span><span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#binary_dice_coefficient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.binary_dice_coefficient" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary dice segmentation loss.</p>
<p>Note:  Assumption is that y_true is <em>not</em> a one-hot representation
of the segmentation batch.  For use with e.g., sigmoid activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>smoothing_factor</strong> (<em>float</em>) – Used to smooth value during optimization</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Loss value (negative Dice coefficient)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.multilabel_dice_coefficient">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">multilabel_dice_coefficient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dimensionality</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">smoothing_factor</span><span class="o">=</span><span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#multilabel_dice_coefficient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.multilabel_dice_coefficient" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-label dice segmentation loss</p>
<p>Note:  Assumption is that y_true is a one-hot representation
of the segmentation batch.  The background (label 0) should
be included but is not used in the calculation.  For use with
e.g., softmax activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dimensionality</strong> (<em>dimensionality</em>) – Image dimension</p></li>
<li><p><strong>smoothing_factor</strong> (<em>float</em>) – Used to smooth value during optimization</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Loss value (negative Dice coefficient)</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">antspynet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r16</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r16_seg</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">kmeans_segmentation</span><span class="p">(</span><span class="n">r16</span><span class="p">,</span> <span class="mi">3</span><span class="p">)[</span><span class="s1">&#39;segmentation&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r16_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">r16_seg</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r16_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">antspynet</span><span class="o">.</span><span class="n">encode_unet</span><span class="p">(</span><span class="n">r16_array</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64_seg</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">kmeans_segmentation</span><span class="p">(</span><span class="n">r64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)[</span><span class="s1">&#39;segmentation&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">r64_seg</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">antspynet</span><span class="o">.</span><span class="n">encode_unet</span><span class="p">(</span><span class="n">r64_array</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dice_loss</span> <span class="o">=</span> <span class="n">antspynet</span><span class="o">.</span><span class="n">multilabel_dice_coefficient</span><span class="p">(</span><span class="n">dimensionality</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_value</span> <span class="o">=</span> <span class="n">dice_loss</span><span class="p">(</span><span class="n">r16_tensor</span><span class="p">,</span> <span class="n">r64_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compare with...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ants</span><span class="o">.</span><span class="n">label_overlap_measures</span><span class="p">(</span><span class="n">r16_seg</span><span class="p">,</span> <span class="n">r64_seg</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.peak_signal_to_noise_ratio">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">peak_signal_to_noise_ratio</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_pred</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#peak_signal_to_noise_ratio"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.peak_signal_to_noise_ratio" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.pearson_correlation_coefficient">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">pearson_correlation_coefficient</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_pred</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#pearson_correlation_coefficient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.pearson_correlation_coefficient" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.categorical_focal_loss">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">categorical_focal_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gamma</span><span class="o">=</span><span class="default_value">2.0</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.25</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#categorical_focal_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.categorical_focal_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.weighted_categorical_crossentropy">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">weighted_categorical_crossentropy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weights</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#weighted_categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.weighted_categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.multilabel_surface_loss">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">multilabel_surface_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dimensionality</span><span class="o">=</span><span class="default_value">3</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#multilabel_surface_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.multilabel_surface_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="antspynet.maximum_mean_discrepancy">
<code class="sig-prename descclassname">antspynet.</code><code class="sig-name descname">maximum_mean_discrepancy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_metrics.html#maximum_mean_discrepancy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.maximum_mean_discrepancy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="custom-normalization-layers">
<h2>Custom normalization layers<a class="headerlink" href="#custom-normalization-layers" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.InstanceNormalization">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">InstanceNormalization</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_normalization_layers.html#InstanceNormalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.InstanceNormalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Instance normalization layer.</p>
<p>Normalize the activations of the previous layer at each step,
i.e. applies a transformation that maintains the mean activation
close to 0 and the activation standard deviation close to 1.</p>
<p>Taken from</p>
<p><a class="reference external" href="https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/layers/normalization/instancenormalization.py">https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/layers/normalization/instancenormalization.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>integer</em>) – Integer specifying which axis should be normalized, typically
the feature axis.  For example, after a Conv2D layer with
<cite>channels_first</cite>, set axis = 1.  Setting <cite>axis=-1L</cite> will
normalize all values in each instance of the batch.  Axis 0
is the batch dimension for tensorflow backend so we throw an
error if <cite>axis = 0</cite>.</p></li>
<li><p><strong>epsilon</strong> (<em>float</em>) – Small float added to variance to avoid dividing by zero.</p></li>
<li><p><strong>center</strong> (If True, add offset of <cite>beta</cite> to normalized tensor.) – If False, <cite>beta</cite> is ignored.</p></li>
<li><p><strong>scale</strong> (If True, multiply by <cite>gamma</cite>.) – If False, <cite>gamma</cite> is not used.  When the next layer is linear (also e.g.,
<cite>nn.relu</cite>), this can be disabled since the scaling will be done by the
next layer.</p></li>
<li><p><strong>beta_initializer</strong> (<em>string</em>) – Initializer for the beta weight.</p></li>
<li><p><strong>gamma_initializer</strong> (<em>string</em>) – Initializer for the gamma weight.</p></li>
<li><p><strong>beta_regularizer</strong> (<em>string</em>) – Optional regularizer for the beta weight.</p></li>
<li><p><strong>gamma_regularizer</strong> (<em>string</em>) – Optional regularizer for the gamma weight.</p></li>
<li><p><strong>beta_constraint</strong> (<em>string</em>) – Optional constraint for the beta weight.</p></li>
<li><p><strong>gamma_constraint</strong> (<em>string</em>) – Optional constraint for the gamma weight.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras layer</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="custom-activation-layers">
<h2>Custom activation layers<a class="headerlink" href="#custom-activation-layers" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.LogSoftmax">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">LogSoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/custom_activation_layers.html#LogSoftmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.LogSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Log Softmax activation function.</p>
<dl class="simple">
<dt>Input shape:</dt><dd><p>Arbitrary. Use the keyword argument <cite>input_shape</cite>
(tuple of integers, does not include the samples axis)
when using this layer as the first layer in a model.</p>
</dd>
<dt>Output shape:</dt><dd><p>Same shape as the input.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> – Integer, axis along which the softmax normalization is applied.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="resample-tensor-layer">
<h2>Resample tensor layer<a class="headerlink" href="#resample-tensor-layer" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.ResampleTensorLayer2D">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">ResampleTensorLayer2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/resample_tensor_utilities.html#ResampleTensorLayer2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.ResampleTensorLayer2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor resampling layer (2D).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>tuple</em>) – Specifies the output shape of the resampled tensor.</p></li>
<li><p><strong>interpolation_type</strong> (<em>string</em>) – One of ‘nearest_neighbor’, ‘linear’, or ‘cubic’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="antspynet.utilities.ResampleTensorLayer3D">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">ResampleTensorLayer3D</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/resample_tensor_utilities.html#ResampleTensorLayer3D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.ResampleTensorLayer3D" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor resampling layer (3D).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>tuple</em>) – Specifies the output shape of the resampled tensor.</p></li>
<li><p><strong>interpolation_type</strong> (<em>string</em>) – One of ‘nearest_neighbor’, ‘linear’, or ‘cubic’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras layer</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="mixture-density-networks">
<h2>Mixture density networks<a class="headerlink" href="#mixture-density-networks" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.MixtureDensityLayer">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">MixtureDensityLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/mixture_density_utilities.html#MixtureDensityLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.MixtureDensityLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer for modeling arbitrary functions using neural networks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_dimension</strong> (<em>integer</em>) – Dimensionality of the output.</p></li>
<li><p><strong>number_of_mixtures</strong> (<em>integer</em>) – Number of gaussians used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.get_mixture_density_loss_function">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">get_mixture_density_loss_function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output_dimension</span></em>, <em class="sig-param"><span class="n">number_of_mixtures</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/mixture_density_utilities.html#get_mixture_density_loss_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.get_mixture_density_loss_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a loss function for the mixture density.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_dimension</strong> (<em>integer</em>) – Dimensionality of the output.</p></li>
<li><p><strong>number_of_mixtures</strong> (<em>integer</em>) – Number of gaussians used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A function providing the mean square error accuracy</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Function</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="attention">
<h2>Attention<a class="headerlink" href="#attention" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.AttentionLayer2D">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">AttentionLayer2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/attention_utilities.html#AttentionLayer2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.AttentionLayer2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Attention layer (2-D) from the self attention GAN</p>
<p>taken from the following python implementation</p>
<p><a class="reference external" href="https://stackoverflow.com/questions/50819931/self-attention-gan-in-keras">https://stackoverflow.com/questions/50819931/self-attention-gan-in-keras</a></p>
<p>based on the following paper:</p>
<p><a class="reference external" href="https://arxiv.org/abs/1805.08318">https://arxiv.org/abs/1805.08318</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>number_of_channels</strong> (<em>integer</em>) – Number of channels</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="antspynet.utilities.AttentionLayer3D">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">AttentionLayer3D</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/attention_utilities.html#AttentionLayer3D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.AttentionLayer3D" title="Permalink to this definition">¶</a></dt>
<dd><p>Attention layer (3-D) from the self attention GAN</p>
<p>taken from the following python implementation</p>
<p><a class="reference external" href="https://stackoverflow.com/questions/50819931/self-attention-gan-in-keras">https://stackoverflow.com/questions/50819931/self-attention-gan-in-keras</a></p>
<p>based on the following paper:</p>
<p><a class="reference external" href="https://arxiv.org/abs/1805.08318">https://arxiv.org/abs/1805.08318</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>number_of_channels</strong> (<em>integer</em>) – Number of channels</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Layer</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">number_of_filters</span> <span class="o">=</span> <span class="mi">64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="n">number_of_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">AttentionLayer2D</span><span class="p">(</span><span class="n">number_of_channels</span><span class="o">=</span><span class="n">number_of_filters</span><span class="p">)(</span><span class="n">outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="clustering">
<h2>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.DeepEmbeddedClustering">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">DeepEmbeddedClustering</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/deep_embedded_clustering_utilities.html#DeepEmbeddedClustering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.DeepEmbeddedClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>Deep embedded lustering layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>number_of_clusters</strong> (<em>integer</em>) – Specifies which axis to normalize.</p></li>
<li><p><strong>initial_cluster_weights</strong> (<em>list</em>) – Initial clustering weights.</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em>) – Parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="antspynet.utilities.DeepEmbeddedClusteringModel">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">DeepEmbeddedClusteringModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">number_of_units_per_layer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">number_of_clusters</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">initializer</span><span class="o">=</span><span class="default_value">'glorot_uniform'</span></em>, <em class="sig-param"><span class="n">convolutional</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">input_image_size</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/deep_embedded_clustering_utilities.html#DeepEmbeddedClusteringModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.DeepEmbeddedClusteringModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Deep embedded clustering with and without convolutions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>number_of_units_per_layer</strong> (<em>integer</em>) – Autoencoder number of units per layer.</p></li>
<li><p><strong>number_of_clusters</strong> (<em>integer</em>) – Number of clusters.</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em>) – Parameter</p></li>
<li><p><strong>initializer</strong> (<em>string</em>) – Initializer for autoencoder.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A keras clustering model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras model</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="image-patch">
<h2>Image patch<a class="headerlink" href="#image-patch" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="antspynet.utilities.extract_image_patches">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">extract_image_patches</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">patch_size</span></em>, <em class="sig-param"><span class="n">max_number_of_patches</span><span class="o">=</span><span class="default_value">'all'</span></em>, <em class="sig-param"><span class="n">stride_length</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">mask_image</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">random_seed</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">return_as_array</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">randomize</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/extract_image_patches.html#extract_image_patches"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.extract_image_patches" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract 2-D or 3-D image patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – Input image with one or more components.</p></li>
<li><p><strong>patch_size</strong> (<em>n-D tuple</em><em> (</em><em>depending on dimensionality</em><em>)</em><em></em>) – Width, height, and depth (if 3-D) of patches.</p></li>
<li><p><strong>max_number_of_patches</strong> (<em>integer</em><em> or </em><em>string</em>) – Maximum number of patches returned.  If “all” is specified, then
all patches in sequence (defined by the stride_length are extracted.</p></li>
<li><p><strong>stride_length</strong> (<em>integer</em><em> or </em><em>n-D tuple</em>) – Defines the sequential patch overlap for max_number_of_patches = “all”.
Can be a image-dimensional vector or a scalar.</p></li>
<li><p><strong>mask_image</strong> (<em>ANTsImage</em><em> (</em><em>optional</em><em>)</em>) – Optional image specifying the sampling region for
the patches when max_number_of_patches does not equal “all”.
The way we constrain patch selection using a mask is by forcing
each returned patch to have a masked voxel at its center.</p></li>
<li><p><strong>random_seed</strong> (<em>integer</em><em> (</em><em>optional</em><em>)</em>) – Seed value that allows reproducible patch extraction across runs.</p></li>
<li><p><strong>return_as_array</strong> (<em>boolean</em>) – Specifies the return type of the function.  If
False (default) the return type is a list where each element is
a single patch.  Otherwise the return type is an array of size
dim( number_of_patches, patch_size ).</p></li>
<li><p><strong>randomize</strong> (<em>boolean</em>) – Boolean controlling whether we randomize indices when masking.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A list (or array) of patches.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_patches</span> <span class="o">=</span> <span class="n">extract_image_patches</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.reconstruct_image_from_patches">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">reconstruct_image_from_patches</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">patches</span></em>, <em class="sig-param"><span class="n">domain_image</span></em>, <em class="sig-param"><span class="n">stride_length</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">domain_image_is_mask</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/reconstruct_image_from_patches.html#reconstruct_image_from_patches"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.reconstruct_image_from_patches" title="Permalink to this definition">¶</a></dt>
<dd><p>Reconstruct image from a list of patches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patches</strong> (<em>list</em><em> or </em><em>array of patches</em>) – List or array of patches defining an image.  Patches are assumed
to have the same format as returned by extract_image_patches.</p></li>
<li><p><strong>domain_image</strong> (<em>ANTs image</em>) – Image or mask to define the geometric information of the
reconstructed image.  If this is a mask image, the reconstruction will only
use patches in the mask.</p></li>
<li><p><strong>stride_length</strong> (<em>integer</em><em> or </em><em>n-D tuple</em>) – Defines the sequential patch overlap for max_number_of_patches = “all”.
Can be a image-dimensional vector or a scalar.</p></li>
<li><p><strong>domain_image_is_mask</strong> (<em>boolean</em>) – Boolean specifying whether the domain image is a
mask used to limit the region of reconstruction from the patches.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>An ANTs image.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_patches</span> <span class="o">=</span> <span class="n">extract_image_patches</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">stride_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reconstructed_image</span> <span class="o">=</span> <span class="n">reconstruct_image_from_patches</span><span class="p">(</span><span class="n">image_patches</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">stride_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="super-resolution">
<h2>Super-resolution<a class="headerlink" href="#super-resolution" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="antspynet.utilities.mse">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">mse</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/super_resolution_utilities.html#mse"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.mse" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean square error of a single image or between two images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>input image</em>) – ants input image</p></li>
<li><p><strong>y</strong> (<em>input image</em>) – ants input image</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Value.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r16</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">r16</span><span class="p">,</span> <span class="n">r64</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.mae">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">mae</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/super_resolution_utilities.html#mae"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.mae" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean absolute error of a single image or between two images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>input image</em>) – ants input image</p></li>
<li><p><strong>y</strong> (<em>input image</em>) – ants input image</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Value</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r16</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">mae</span><span class="p">(</span><span class="n">r16</span><span class="p">,</span> <span class="n">r64</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.psnr">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">psnr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/super_resolution_utilities.html#psnr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.psnr" title="Permalink to this definition">¶</a></dt>
<dd><p>Peak signal-to-noise ratio between two images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>input image</em>) – ants input image</p></li>
<li><p><strong>y</strong> (<em>input image</em>) – ants input image</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Value</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r16</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">psnr</span><span class="p">(</span><span class="n">r16</span><span class="p">,</span> <span class="n">r64</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.ssim">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">ssim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">K</span><span class="o">=</span><span class="default_value">0.01, 0.03</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/super_resolution_utilities.html#ssim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.ssim" title="Permalink to this definition">¶</a></dt>
<dd><p>Structural similarity index (SSI) between two images.</p>
<p>Implementation of the SSI quantity for two images proposed in</p>
<p>Z. Wang, A.C. Bovik, H.R. Sheikh, E.P. Simoncelli. “Image quality
assessment: from error visibility to structural similarity”. IEEE TIP.
13 (4): 600–612.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>input image</em>) – ants input image</p></li>
<li><p><strong>y</strong> (<em>input image</em>) – ants input image</p></li>
<li><p><strong>K</strong> (<em>tuple of length 2</em>) – tuple which contain SSI parameters meant to stabilize the formula
in case of weak denominators.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Value</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r16</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">psnr</span><span class="p">(</span><span class="n">r16</span><span class="p">,</span> <span class="n">r64</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.gmsd">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">gmsd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/super_resolution_utilities.html#gmsd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.gmsd" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradient magnitude similarity deviation</p>
<p>A fast and simple metric that correlates to perceptual quality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>input image</em>) – ants input image</p></li>
<li><p><strong>y</strong> (<em>input image</em>) – ants input image</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Value</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r16</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r64</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">gmsd</span><span class="p">(</span><span class="n">r16</span><span class="p">,</span> <span class="n">r64</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.apply_super_resolution_model_to_image">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">apply_super_resolution_model_to_image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">target_range</span><span class="o">=</span><span class="default_value">- 127.5, 127.5</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">32</span></em>, <em class="sig-param"><span class="n">regression_order</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/super_resolution_utilities.html#apply_super_resolution_model_to_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.apply_super_resolution_model_to_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply a pretrained deep back projection model for super resolution.
Helper function for applying a pretrained deep back projection model.
Apply a patch-wise trained network to perform super-resolution. Can be applied
to variable sized inputs. Warning: This function may be better used on CPU
unless the GPU can accommodate the full image size. Warning 2: The global
intensity range (min to max) of the output will match the input where the
range is taken over all channels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTs image</em>) – input image.</p></li>
<li><p><strong>model</strong> (<em>keras object</em><em> or </em><em>string</em>) – pretrained keras model or filename.</p></li>
<li><p><strong>target_range</strong> (<em>2-element tuple</em>) – a tuple or array defining the (min, max) of the input image
(e.g., -127.5, 127.5).  Output images will be scaled back to original
intensity. This range should match the mapping used in the training
of the network.</p></li>
<li><p><strong>batch_size</strong> (<em>integer</em>) – Batch size used for the prediction call.</p></li>
<li><p><strong>regression_order</strong> (<em>integer</em>) – If specified, Apply the function regression_match_image with
poly_order=regression_order.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – If True, show status messages.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Super-resolution image upscaled to resolution specified by the network.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_sr</span> <span class="o">=</span> <span class="n">apply_super_resolution_model_to_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">get_pretrained_network</span><span class="p">(</span><span class="s2">&quot;dbpn4x&quot;</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="spatial-transformer-network">
<h2>Spatial transformer network<a class="headerlink" href="#spatial-transformer-network" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="antspynet.utilities.SpatialTransformer2D">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">SpatialTransformer2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/spatial_transformer_network_utilities.html#SpatialTransformer2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.SpatialTransformer2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Custom layer for the spatial transfomer network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>list of size 2</em>) – The first element are the images and the second element are the
weights.</p></li>
<li><p><strong>resampled_size</strong> (<em>tuple of length 2</em>) – Size of the resampled output images.</p></li>
<li><p><strong>transform_type</strong> (<em>string</em>) – Transform type (default = ‘affine’).</p></li>
<li><p><strong>interpolator_type</strong> (<em>string</em>) – Interpolator type (default = ‘linear’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A 2-D keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="antspynet.utilities.SpatialTransformer3D">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">SpatialTransformer3D</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/spatial_transformer_network_utilities.html#SpatialTransformer3D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.SpatialTransformer3D" title="Permalink to this definition">¶</a></dt>
<dd><p>Custom layer for the spatial transfomer network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>list of size 2</em>) – The first element are the images and the second element are the
weights.</p></li>
<li><p><strong>resampled_size</strong> (<em>tuple of length 3</em>) – Size of the resampled output images.</p></li>
<li><p><strong>transform_type</strong> (<em>string</em>) – Transform type (default = ‘affine’).</p></li>
<li><p><strong>interpolator_type</strong> (<em>string</em>) – Interpolator type (default = ‘linear’).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A 3-D keras layer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Keras layer</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="applications">
<h2>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="antspynet.utilities.brain_extraction">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">brain_extraction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">modality</span><span class="o">=</span><span class="default_value">'t1v0'</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/brain_extraction.html#brain_extraction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.brain_extraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform brain extraction using U-net and ANTs-based training data.  “NoBrainer”
is also possible where brain extraction uses U-net and FreeSurfer training data
ported from the</p>
<p><a class="reference external" href="https://github.com/neuronets/nobrainer-models">https://github.com/neuronets/nobrainer-models</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – input image (or list of images for multi-modal scenarios).</p></li>
<li><p><strong>modality</strong> (<em>string</em>) – <dl class="simple">
<dt>Modality image type.  Options include:</dt><dd><ul>
<li><p>”t1”: T1-weighted MRI—ANTs-trained.  Update from “t1v0”.</p></li>
<li><p>”t1v0”:  T1-weighted MRI—ANTs-trained.</p></li>
<li><p>”t1nobrainer”: T1-weighted MRI—FreeSurfer-trained: h/t Satra Ghosh and Jakub Kaczmarzyk.</p></li>
<li><dl class="simple">
<dt>”t1combined”: Brian’s combination of “t1” and “t1nobrainer”.  One can also specify</dt><dd><p>”t1combined[X]” where X is the morphological radius.  X = 12 by default.</p>
</dd>
</dl>
</li>
<li><p>”flair”: FLAIR MRI.</p></li>
<li><p>”t2”: T2 MRI.</p></li>
<li><p>”bold”: 3-D BOLD MRI.</p></li>
<li><p>”fa”: Fractional anisotropy.</p></li>
<li><p>”t1t2infant”: Combined T1-w/T2-w infant MRI h/t Martin Styner.</p></li>
<li><p>”t1infant”: T1-w infant MRI h/t Martin Styner.</p></li>
<li><p>”t2infant”: T2-w infant MRI h/t Martin Styner.</p></li>
</ul>
</dd>
</dl>
</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ANTs probability brain mask image.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">probability_brain_mask</span> <span class="o">=</span> <span class="n">brain_extraction</span><span class="p">(</span><span class="n">brain_image</span><span class="p">,</span> <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;t1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.cortical_thickness">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">cortical_thickness</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/cortical_thickness.html#cortical_thickness"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.cortical_thickness" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform KellyKapowski cortical thickness using deep_atropos for
segmentation.  Description concerning implementaiton and evaluation:</p>
<p><a class="reference external" href="https://www.medrxiv.org/content/10.1101/2020.10.19.20215392v1">https://www.medrxiv.org/content/10.1101/2020.10.19.20215392v1</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – input 3-D unprocessed T1-weighted brain image.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Cortical thickness image and segmentation probability images.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1w_image.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kk</span> <span class="o">=</span> <span class="n">cortical_thickness</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.longitudinal_cortical_thickness">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">longitudinal_cortical_thickness</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1s</span></em>, <em class="sig-param"><span class="n">initial_template</span><span class="o">=</span><span class="default_value">'oasis'</span></em>, <em class="sig-param"><span class="n">number_of_iterations</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">refinement_transform</span><span class="o">=</span><span class="default_value">'antsRegistrationSyNQuick[a]'</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/cortical_thickness.html#longitudinal_cortical_thickness"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.longitudinal_cortical_thickness" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform KellyKapowski cortical thickness longitudinally using code{deepAtropos}
for segmentation of the derived single-subject template.  It takes inspiration from
the work described here:</p>
<p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/31356207/">https://pubmed.ncbi.nlm.nih.gov/31356207/</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1s</strong> (<em>list of ANTsImage</em>) – Input list of 3-D unprocessed t1-weighted brain images from a single subject.</p></li>
<li><p><strong>initial_template</strong> (<em>string</em><em> or </em><em>ANTsImage</em>) – Input image to define the orientation of the SST.  Can be a string (see
get_antsxnet_data) or a specified template.  This allows the user to create a
SST outside of this routine.</p></li>
<li><p><strong>number_of_iterations</strong> (<em>int</em>) – Defines the number of iterations for refining the SST.</p></li>
<li><p><strong>refinement_transform</strong> (<em>string</em>) – Transform for defining the refinement registration transform. See options in
ants.registration.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Cortical thickness image and segmentation probability images.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t1s</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1w_image.nii.gz&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kk</span> <span class="o">=</span> <span class="n">longitudinal_cortical_thickness</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.lung_extraction">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">lung_extraction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">modality</span><span class="o">=</span><span class="default_value">'proton'</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/lung_extraction.html#lung_extraction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.lung_extraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform proton or ct lung extraction using U-net.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – input image</p></li>
<li><p><strong>modality</strong> (<em>string</em>) – Modality image type.  Options include “ct”, “proton”, “protonLobes”,
“maskLobes”, and “ventilation”.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dictionary of ANTs segmentation and probability images.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">lung_extraction</span><span class="p">(</span><span class="n">lung_image</span><span class="p">,</span> <span class="n">modality</span><span class="o">=</span><span class="s2">&quot;proton&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.preprocess_brain_image">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">preprocess_brain_image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">truncate_intensity</span><span class="o">=</span><span class="default_value">0.01, 0.99</span></em>, <em class="sig-param"><span class="n">brain_extraction_modality</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">template_transform_type</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">template</span><span class="o">=</span><span class="default_value">'biobank'</span></em>, <em class="sig-param"><span class="n">do_bias_correction</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">return_bias_field</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_denoising</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">intensity_matching_type</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">reference_image</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">intensity_normalization_type</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/preprocess_image.html#preprocess_brain_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.preprocess_brain_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic preprocessing pipeline for T1-weighted brain MRI</p>
<p>Standard preprocessing steps that have been previously described
in various papers including the cortical thickness pipeline:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/24879923">https://www.ncbi.nlm.nih.gov/pubmed/24879923</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – input image</p></li>
<li><p><strong>truncate_intensity</strong> (<em>2-length tuple</em>) – Defines the quantile threshold for truncating the image intensity</p></li>
<li><p><strong>brain_extraction_modality</strong> (<em>string</em><em> or </em><em>None</em>) – Perform brain extraction using antspynet tools.  One of “t1”, “t1v0”,
“t1nobrainer”, “t1combined”, “flair”, “t2”, “bold”, “fa”, “t1infant”,
“t2infant”, or None.</p></li>
<li><p><strong>template_transform_type</strong> (<em>string</em>) – See details in help for ants.registration.  Typically “Rigid” or
“Affine”.</p></li>
<li><p><strong>template</strong> (<em>ANTs image</em><em> (</em><em>not skull-stripped</em><em>)</em>) – Alternatively, one can specify the default “biobank” or “croppedMni152”
to download and use premade templates.</p></li>
<li><p><strong>do_bias_correction</strong> (<em>boolean</em>) – Perform N4 bias field correction.</p></li>
<li><p><strong>return_bias_field</strong> (<em>boolean</em>) – If True, return bias field as an additional output <em>without</em> bias
correcting the preprocessed image.</p></li>
<li><p><strong>do_denoising</strong> (<em>boolean</em>) – Perform non-local means denoising.</p></li>
<li><p><strong>intensity_matching_type</strong> (<em>string</em>) – Either “regression” or “histogram”. Only is performed if reference_image
is not None.</p></li>
<li><p><strong>reference_image</strong> (<em>ANTs image</em>) – Reference image for intensity matching.</p></li>
<li><p><strong>intensity_normalization_type</strong> (<em>string</em>) – Either rescale the intensities to [0,1] (i.e., “01”) or zero-mean, unit variance
(i.e., “0mean”).  If None normalization is not performed.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>Dictionary with preprocessing information ANTs image (i.e., source_image) matched to the</em></p></li>
<li><p><em>(reference_image).</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">preprocessed_image</span> <span class="o">=</span> <span class="n">preprocess_brain_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">do_brain_extraction</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.sysu_media_wmh_segmentation">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">sysu_media_wmh_segmentation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">flair</span></em>, <em class="sig-param"><span class="n">t1</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_ensemble</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/white_matter_hyperintensity_segmentation.html#sysu_media_wmh_segmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.sysu_media_wmh_segmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform WMH segmentation using the winning submission in the MICCAI
2017 challenge by the sysu_media team using FLAIR or T1/FLAIR.  The
MICCAI challenge is discussed in</p>
<p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/30908194/">https://pubmed.ncbi.nlm.nih.gov/30908194/</a></p>
<p>with the sysu_media’s team entry is discussed in</p>
<blockquote>
<div><p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/30125711/">https://pubmed.ncbi.nlm.nih.gov/30125711/</a></p>
</div></blockquote>
<p>with the original implementation available here:</p>
<p><a class="reference external" href="https://github.com/hongweilibran/wmh_ibbmTum">https://github.com/hongweilibran/wmh_ibbmTum</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>flair</strong> (<em>ANTsImage</em>) – input 3-D FLAIR brain image (not skull-stripped).</p></li>
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – input 3-D T1 brain image (not skull-stripped).</p></li>
<li><p><strong>use_ensemble</strong> (<em>boolean</em>) – check whether to use all 3 sets of weights.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>WMH segmentation probability image</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;flair.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">probability_mask</span> <span class="o">=</span> <span class="n">sysu_media_wmh_segmentation</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.claustrum_segmentation">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">claustrum_segmentation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">do_preprocessing</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_ensemble</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/claustrum_segmentation.html#claustrum_segmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.claustrum_segmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Claustrum segmentation</p>
<p>Described here:</p>
<blockquote>
<div><p><a class="reference external" href="https://arxiv.org/abs/2008.03465">https://arxiv.org/abs/2008.03465</a></p>
</div></blockquote>
<p>with the implementation available at:</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/hongweilibran/claustrum_multi_view">https://github.com/hongweilibran/claustrum_multi_view</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – input 3-D T1 brain image.</p></li>
<li><p><strong>do_preprocessing</strong> (<em>boolean</em>) – perform n4 bias correction.</p></li>
<li><p><strong>use_ensemble</strong> (<em>boolean</em>) – check whether to use all 3 sets of weights.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Claustrum segmentation probability image</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">probability_mask</span> <span class="o">=</span> <span class="n">claustrum_segmentation</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.hypothalamus_segmentation">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">hypothalamus_segmentation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/hypothalamus_segmentation.html#hypothalamus_segmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.hypothalamus_segmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Hypothalamus and subunits segmentation</p>
<p>Described here:</p>
<blockquote>
<div><p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/32853816/">https://pubmed.ncbi.nlm.nih.gov/32853816/</a></p>
</div></blockquote>
<p>ported from the original implementation</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/BBillot/hypothalamus_seg">https://github.com/BBillot/hypothalamus_seg</a></p>
</div></blockquote>
<p>Subunits labeling:</p>
<p>Label 1:  left anterior-inferior
Label 2:  left anterior-superior
Label 3:  left posterior
Label 4:  left tubular inferior
Label 5:  left tubular superior
Label 6:  right anterior-inferior
Label 7:  right anterior-superior
Label 8:  right posterior
Label 9:  right tubular inferior
Label 10: right tubular superior</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – input 3-D T1 brain image.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Hypothalamus segmentation (and subunits) probability images</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypo</span> <span class="o">=</span> <span class="n">hypothalamus_segmentation</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.hippmapp3r_segmentation">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">hippmapp3r_segmentation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">do_preprocessing</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/hippmapp3r_segmentation.html#hippmapp3r_segmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.hippmapp3r_segmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform HippMapp3r (hippocampal) segmentation described in</p>
<blockquote>
<div><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/31609046">https://www.ncbi.nlm.nih.gov/pubmed/31609046</a></p>
</div></blockquote>
<p>with models and architecture ported from</p>
<p><a class="reference external" href="https://github.com/mgoubran/HippMapp3r">https://github.com/mgoubran/HippMapp3r</a></p>
<p>Additional documentation and attribution resources found at</p>
<p><a class="reference external" href="https://hippmapp3r.readthedocs.io/en/latest/">https://hippmapp3r.readthedocs.io/en/latest/</a></p>
<dl class="simple">
<dt>Preprocessing consists of:</dt><dd><ul class="simple">
<li><p>n4 bias correction and</p></li>
<li><p>brain extraction</p></li>
</ul>
</dd>
</dl>
<p>The input T1 should undergo the same steps.  If the input T1 is the raw
T1, these steps can be performed by the internal preprocessing, i.e. set
do_preprocessing = True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – input image</p></li>
<li><p><strong>do_preprocessing</strong> (<em>boolean</em>) – See description above.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ANTs labeled hippocampal image.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">hippmapp3r_segmentation</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.deep_flash">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">deep_flash</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">t2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">do_preprocessing</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/deep_flash.html#deep_flash"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.deep_flash" title="Permalink to this definition">¶</a></dt>
<dd><p>Hippocampal/Enthorhinal segmentation using “Deep Flash”</p>
<p>Perform hippocampal/entorhinal segmentation in T1 images using
labels from Mike Yassa’s lab</p>
<p><a class="reference external" href="https://faculty.sites.uci.edu/myassa/">https://faculty.sites.uci.edu/myassa/</a></p>
<p>The labeling is as follows:
Label 0 :  background
Label 5 :  left aLEC
Label 6 :  right aLEC
Label 7 :  left pMEC
Label 8 :  right pMEC
Label 9 :  left perirhinal
Label 10:  right perirhinal
Label 11:  left parahippocampal
Label 12:  right parahippocampal
Label 13:  left DG/CA3
Label 14:  right DG/CA3
Label 15:  left CA1
Label 16:  right CA1
Label 17:  left subiculum
Label 18:  right subiculum</p>
<dl class="simple">
<dt>Preprocessing on the training data consisted of:</dt><dd><ul class="simple">
<li><p>n4 bias correction,</p></li>
<li><p>denoising,</p></li>
<li><p>affine registration to the “deep flash” template.</p></li>
</ul>
</dd>
</dl>
<p>The input T1 should undergo the same steps.  If the input T1 is the raw
T1, these steps can be performed by the internal preprocessing, i.e. set
do_preprocessing = True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – raw or preprocessed 3-D T1-weighted brain image.</p></li>
<li><p><strong>t2</strong> (<em>ANTsImage</em>) – Optional 3-D T2-weighted brain image.  If specified, it is assumed to be
pre-aligned to the t1.</p></li>
<li><p><strong>do_preprocessing</strong> (<em>boolean</em>) – See description above.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>List consisting of the segmentation image and probability images for</em></p></li>
<li><p><em>each label and foreground.</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flash</span> <span class="o">=</span> <span class="n">deep_flash</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.deep_atropos">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">deep_atropos</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">do_preprocessing</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_spatial_priors</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/deep_atropos.html#deep_atropos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.deep_atropos" title="Permalink to this definition">¶</a></dt>
<dd><p>Six-tissue segmentation.</p>
<p>Perform Atropos-style six tissue segmentation using deep learning.</p>
<p>The labeling is as follows:
Label 0 :  background
Label 1 :  CSF
Label 2 :  gray matter
Label 3 :  white matter
Label 4 :  deep gray matter
Label 5 :  brain stem
Label 6 :  cerebellum</p>
<dl class="simple">
<dt>Preprocessing on the training data consisted of:</dt><dd><ul class="simple">
<li><p>n4 bias correction,</p></li>
<li><p>denoising,</p></li>
<li><p>brain extraction, and</p></li>
<li><p>affine registration to MNI.</p></li>
</ul>
</dd>
</dl>
<p>The input T1 should undergo the same steps.  If the input T1 is the raw
T1, these steps can be performed by the internal preprocessing, i.e. set
do_preprocessing = True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – raw or preprocessed 3-D T1-weighted brain image.</p></li>
<li><p><strong>do_preprocessing</strong> (<em>boolean</em>) – See description above.</p></li>
<li><p><strong>use_spatial_priors</strong> (<em>integer</em>) – Use MNI spatial tissue priors (0 or 1).  Currently, only ‘0’ (no priors) and ‘1’
(cerebellar prior only) are the only two options.  Default is 1.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>List consisting of the segmentation image and probability images for</em></p></li>
<li><p><em>each label.</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flash</span> <span class="o">=</span> <span class="n">deep_atropos</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.desikan_killiany_tourville_labeling">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">desikan_killiany_tourville_labeling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">do_preprocessing</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">return_probability_images</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">do_lobar_parcellation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/desikan_killiany_tourville_labeling.html#desikan_killiany_tourville_labeling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.desikan_killiany_tourville_labeling" title="Permalink to this definition">¶</a></dt>
<dd><p>Cortical and deep gray matter labeling using Desikan-Killiany-Tourville</p>
<p>Perform DKT labeling using deep learning</p>
<p>The labeling is as follows:</p>
<p>Inner labels:
Label 0: background
Label 4: left lateral ventricle
Label 5: left inferior lateral ventricle
Label 6: left cerebellem exterior
Label 7: left cerebellum white matter
Label 10: left thalamus proper
Label 11: left caudate
Label 12: left putamen
Label 13: left pallidium
Label 15: 4th ventricle
Label 16: brain stem
Label 17: left hippocampus
Label 18: left amygdala
Label 24: CSF
Label 25: left lesion
Label 26: left accumbens area
Label 28: left ventral DC
Label 30: left vessel
Label 43: right lateral ventricle
Label 44: right inferior lateral ventricle
Label 45: right cerebellum exterior
Label 46: right cerebellum white matter
Label 49: right thalamus proper
Label 50: right caudate
Label 51: right putamen
Label 52: right palladium
Label 53: right hippocampus
Label 54: right amygdala
Label 57: right lesion
Label 58: right accumbens area
Label 60: right ventral DC
Label 62: right vessel
Label 72: 5th ventricle
Label 85: optic chasm
Label 91: left basal forebrain
Label 92: right basal forebrain
Label 630: cerebellar vermal lobules I-V
Label 631: cerebellar vermal lobules VI-VII
Label 632: cerebellar vermal lobules VIII-X</p>
<p>Outer labels:
Label 1002: left caudal anterior cingulate
Label 1003: left caudal middle frontal
Label 1005: left cuneus
Label 1006: left entorhinal
Label 1007: left fusiform
Label 1008: left inferior parietal
Label 1009: left inferior temporal
Label 1010: left isthmus cingulate
Label 1011: left lateral occipital
Label 1012: left lateral orbitofrontal
Label 1013: left lingual
Label 1014: left medial orbitofrontal
Label 1015: left middle temporal
Label 1016: left parahippocampal
Label 1017: left paracentral
Label 1018: left pars opercularis
Label 1019: left pars orbitalis
Label 1020: left pars triangularis
Label 1021: left pericalcarine
Label 1022: left postcentral
Label 1023: left posterior cingulate
Label 1024: left precentral
Label 1025: left precuneus
Label 1026: left rostral anterior cingulate
Label 1027: left rostral middle frontal
Label 1028: left superior frontal
Label 1029: left superior parietal
Label 1030: left superior temporal
Label 1031: left supramarginal
Label 1034: left transverse temporal
Label 1035: left insula
Label 2002: right caudal anterior cingulate
Label 2003: right caudal middle frontal
Label 2005: right cuneus
Label 2006: right entorhinal
Label 2007: right fusiform
Label 2008: right inferior parietal
Label 2009: right inferior temporal
Label 2010: right isthmus cingulate
Label 2011: right lateral occipital
Label 2012: right lateral orbitofrontal
Label 2013: right lingual
Label 2014: right medial orbitofrontal
Label 2015: right middle temporal
Label 2016: right parahippocampal
Label 2017: right paracentral
Label 2018: right pars opercularis
Label 2019: right pars orbitalis
Label 2020: right pars triangularis
Label 2021: right pericalcarine
Label 2022: right postcentral
Label 2023: right posterior cingulate
Label 2024: right precentral
Label 2025: right precuneus
Label 2026: right rostral anterior cingulate
Label 2027: right rostral middle frontal
Label 2028: right superior frontal
Label 2029: right superior parietal
Label 2030: right superior temporal
Label 2031: right supramarginal
Label 2034: right transverse temporal
Label 2035: right insula</p>
<p>Performing the lobar parcellation is based on the FreeSurfer division
described here:</p>
<p>See <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation">https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation</a></p>
<p>Frontal lobe:
Label 1002:  left caudal anterior cingulate
Label 1003:  left caudal middle frontal
Label 1012:  left lateral orbitofrontal
Label 1014:  left medial orbitofrontal
Label 1017:  left paracentral
Label 1018:  left pars opercularis
Label 1019:  left pars orbitalis
Label 1020:  left pars triangularis
Label 1024:  left precentral
Label 1026:  left rostral anterior cingulate
Label 1027:  left rostral middle frontal
Label 1028:  left superior frontal
Label 2002:  right caudal anterior cingulate
Label 2003:  right caudal middle frontal
Label 2012:  right lateral orbitofrontal
Label 2014:  right medial orbitofrontal
Label 2017:  right paracentral
Label 2018:  right pars opercularis
Label 2019:  right pars orbitalis
Label 2020:  right pars triangularis
Label 2024:  right precentral
Label 2026:  right rostral anterior cingulate
Label 2027:  right rostral middle frontal
Label 2028:  right superior frontal</p>
<p>Parietal:
Label 1008:  left inferior parietal
Label 1010:  left isthmus cingulate
Label 1022:  left postcentral
Label 1023:  left posterior cingulate
Label 1025:  left precuneus
Label 1029:  left superior parietal
Label 1031:  left supramarginal
Label 2008:  right inferior parietal
Label 2010:  right isthmus cingulate
Label 2022:  right postcentral
Label 2023:  right posterior cingulate
Label 2025:  right precuneus
Label 2029:  right superior parietal
Label 2031:  right supramarginal</p>
<p>Temporal:
Label 1006:  left entorhinal
Label 1007:  left fusiform
Label 1009:  left inferior temporal
Label 1015:  left middle temporal
Label 1016:  left parahippocampal
Label 1030:  left superior temporal
Label 1034:  left transverse temporal
Label 2006:  right entorhinal
Label 2007:  right fusiform
Label 2009:  right inferior temporal
Label 2015:  right middle temporal
Label 2016:  right parahippocampal
Label 2030:  right superior temporal
Label 2034:  right transverse temporal</p>
<p>Occipital:
Label 1005:  left cuneus
Label 1011:  left lateral occipital
Label 1013:  left lingual
Label 1021:  left pericalcarine
Label 2005:  right cuneus
Label 2011:  right lateral occipital
Label 2013:  right lingual
Label 2021:  right pericalcarine</p>
<p>Other outer labels:
Label 1035:  left insula
Label 2035:  right insula</p>
<dl class="simple">
<dt>Preprocessing on the training data consisted of:</dt><dd><ul class="simple">
<li><p>n4 bias correction,</p></li>
<li><p>denoising,</p></li>
<li><p>brain extraction, and</p></li>
<li><p>affine registration to MNI.</p></li>
</ul>
</dd>
</dl>
<p>The input T1 should undergo the same steps.  If the input T1 is the raw
T1, these steps can be performed by the internal preprocessing, i.e. set
do_preprocessing = True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – raw or preprocessed 3-D T1-weighted brain image.</p></li>
<li><p><strong>do_preprocessing</strong> (<em>boolean</em>) – See description above.</p></li>
<li><p><strong>return_probability_images</strong> (<em>boolean</em>) – Whether to return the two sets of probability images for the inner and outer
labels.</p></li>
<li><p><strong>do_lobar_parcellation</strong> (<em>boolean</em>) – Perform lobar parcellation (also divided by hemisphere).</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>List consisting of the segmentation image and probability images for</em></p></li>
<li><p><em>each label.</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dkt</span> <span class="o">=</span> <span class="n">desikan_killiany_tourville_labeling</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.brain_age">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">brain_age</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t1</span></em>, <em class="sig-param"><span class="n">do_preprocessing</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">number_of_simulations</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">sd_affine</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/brain_age.html#brain_age"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.brain_age" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate BrainAge from a T1-weighted MR image using the DeepBrainNet
architecture and weights described here:</p>
<p><a class="reference external" href="https://github.com/vishnubashyam/DeepBrainNet">https://github.com/vishnubashyam/DeepBrainNet</a></p>
<p>and described in the following article:</p>
<p><a class="reference external" href="https://academic.oup.com/brain/article-abstract/doi/10.1093/brain/awaa160/5863667?redirectedFrom=fulltext">https://academic.oup.com/brain/article-abstract/doi/10.1093/brain/awaa160/5863667?redirectedFrom=fulltext</a></p>
<dl class="simple">
<dt>Preprocessing on the training data consisted of:</dt><dd><ul class="simple">
<li><p>n4 bias correction,</p></li>
<li><p>brain extraction, and</p></li>
<li><p>affine registration to MNI.</p></li>
</ul>
</dd>
</dl>
<p>The input T1 should undergo the same steps.  If the input T1 is the raw
T1, these steps can be performed by the internal preprocessing, i.e. set
do_preprocessing = True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t1</strong> (<em>ANTsImage</em>) – raw or preprocessed 3-D T1-weighted brain image.</p></li>
<li><p><strong>do_preprocessing</strong> (<em>boolean</em>) – See description above.</p></li>
<li><p><strong>number_of_simulations</strong> (<em>integer</em>) – Number of random affine perturbations to transform the input.</p></li>
<li><p><strong>sd_affine</strong> (<em>float</em>) – Define the standard deviation of the affine transformation parameter.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>List consisting of the segmentation image and probability images for</em></p></li>
<li><p><em>each label.</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deep</span> <span class="o">=</span> <span class="n">brain_age</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted age: &quot;</span><span class="p">,</span> <span class="n">deep</span><span class="p">[</span><span class="s1">&#39;predicted_age&#39;</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.mri_super_resolution">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">mri_super_resolution</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/mri_super_resolution.html#mri_super_resolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.mri_super_resolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform super-resolution (2x) of MRI data using deep back projection network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – magnetic resonance image</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The super-resolved image.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;t1.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_sr</span> <span class="o">=</span> <span class="n">mri_super_resolution</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.tid_neural_image_assessment">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">tid_neural_image_assessment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">patch_size</span><span class="o">=</span><span class="default_value">101</span></em>, <em class="sig-param"><span class="n">stride_length</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">padding_size</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">dimensions_to_predict</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">which_model</span><span class="o">=</span><span class="default_value">'tidsQualityAssessment'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/quality_assessment.html#tid_neural_image_assessment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.tid_neural_image_assessment" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform MOS-based assessment of an image.</p>
<p>Use a ResNet architecture to estimate image quality in 2D or 3D using subjective
QC image databases described in</p>
<p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0923596514001490">https://www.sciencedirect.com/science/article/pii/S0923596514001490</a></p>
<p>or</p>
<p><a class="reference external" href="https://doi.org/10.1109/TIP.2020.2967829">https://doi.org/10.1109/TIP.2020.2967829</a></p>
<p>where the image assessment is either “global”, i.e., a single number or an image
based on the specified patch size.  In the 3-D case, neighboring slices are used
for each estimate.  Note that parameters should be kept as consistent as possible
in order to enable comparison.  Patch size should be roughly 1/12th to 1/4th of
image size to enable locality. A global estimate can be gained by setting
patch_size = “global”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em><em> (</em><em>2-D</em><em> or </em><em>3-D</em><em>)</em>) – input image.</p></li>
<li><p><strong>mask</strong> (<em>ANTsImage</em><em> (</em><em>2-D</em><em> or </em><em>3-D</em><em>)</em>) – optional mask for designating calculation ROI.</p></li>
<li><p><strong>patch_size</strong> (<em>integer</em>) – prime number of patch_size.  101 is good.  Otherwise, choose “global” for a single
global estimate of quality.</p></li>
<li><p><strong>stride_length</strong> (<em>integer</em><em> or </em><em>vector of image dimension length</em>) – optional value to speed up computation (typically less than patch size).</p></li>
<li><p><strong>padding_size</strong> (<em>positive</em><em> or </em><em>negative integer</em><em> or </em><em>vector of image dimension length</em>) – de(padding) to remove edge effects.</p></li>
<li><p><strong>dimensions_to_predict</strong> (<em>integer</em><em> or </em><em>vector</em>) – if image dimension is 3, this parameter specifies which dimensions should be used for
prediction.  If more than one dimension is specified, the results are averaged.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>which_model</strong> (<em>string</em>) – model type e.g. string tidsQualityAssessment, koniqMS, koniqMS2 or koniqMS3 where
the former predicts mean opinion score (MOS) and MOS standard deviation and
the latter koniq models predict mean opinion score (MOS) and sharpness.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>List of QC results predicting both both human rater’s mean and standard</em></p></li>
<li><p><em>deviation of the MOS (“mean opinion scores”) or sharpness depending on the</em></p></li>
<li><p><em>selected network.  Both aggregate and spatial scores are returned, the latter</em></p></li>
<li><p><em>in the form of an image.</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">get_mask</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tid</span> <span class="o">=</span> <span class="n">tid_neural_image_assessment</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">stride_length</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.neural_style_transfer">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">neural_style_transfer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">content_image</span></em>, <em class="sig-param"><span class="n">style_images</span></em>, <em class="sig-param"><span class="n">initial_combination_image</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">number_of_iterations</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">learning_rate</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">total_variation_weight</span><span class="o">=</span><span class="default_value">8.5e-05</span></em>, <em class="sig-param"><span class="n">content_weight</span><span class="o">=</span><span class="default_value">0.025</span></em>, <em class="sig-param"><span class="n">style_image_weights</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">content_layer_names</span><span class="o">=</span><span class="default_value">['block5_conv2']</span></em>, <em class="sig-param"><span class="n">style_layer_names</span><span class="o">=</span><span class="default_value">'all'</span></em>, <em class="sig-param"><span class="n">content_mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">style_masks</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">use_shifted_activations</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">use_chained_inference</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">output_prefix</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/neural_style_transfer.html#neural_style_transfer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.neural_style_transfer" title="Permalink to this definition">¶</a></dt>
<dd><p>The popular neural style transfer described here:</p>
<p><a class="reference external" href="https://arxiv.org/abs/1508.06576">https://arxiv.org/abs/1508.06576</a> and <a class="reference external" href="https://arxiv.org/abs/1605.04603">https://arxiv.org/abs/1605.04603</a></p>
<p>and taken from François Chollet’s implementation</p>
<p><a class="reference external" href="https://keras.io/examples/generative/neural_style_transfer/">https://keras.io/examples/generative/neural_style_transfer/</a></p>
<p>and titu1994’s modifications:</p>
<p><a class="reference external" href="https://github.com/titu1994/Neural-Style-Transfer">https://github.com/titu1994/Neural-Style-Transfer</a></p>
<p>in order to possibly modify and experiment with medical images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>content_image</strong> (<em>ANTsImage</em><em> (</em><em>1</em><em> or </em><em>3-component</em><em>)</em>) – Content (or base) image.</p></li>
<li><p><strong>style_images</strong> (<em>ANTsImage</em><em> or </em><em>list of ANTsImages</em>) – Style (or reference) image.</p></li>
<li><p><strong>initial_combination_image</strong> (<em>ANTsImage</em><em> (</em><em>1</em><em> or </em><em>3-component</em><em>)</em>) – Starting point for the optimization.  Allows one to start from the
output from a previous run.  Otherwise, start from the content image.
Note that the original paper starts with a noise image.</p></li>
<li><p><strong>number_of_iterations</strong> (<em>integer</em>) – Number of gradient steps taken during optimization.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – Parameter for Adam optimization.</p></li>
<li><p><strong>total_variation_weight</strong> (<em>float</em>) – A penalty on the regularization term to keep the features
of the output image locally coherent.</p></li>
<li><p><strong>content_weight</strong> (<em>float</em>) – Weight of the content layers in the optimization function.</p></li>
<li><p><strong>style_image_weights</strong> (<em>float</em><em> or </em><em>list of floats</em>) – Weights of the style term in the optimization function for each
style image.  Can either specify a single scalar to be used for
all the images or one for each image.  The
style term computes the sum of the L2 norm between the Gram
matrices of the different layers (using ImageNet-trained VGG)
of the style and content images.</p></li>
<li><p><strong>content_layer_names</strong> (<em>list of strings</em>) – Names of VGG layers from which to compute the content loss.</p></li>
<li><p><strong>style_layer_names</strong> (<em>list of strings</em>) – <p>Names of VGG layers from which to compute the style loss.  If “all”,
the layers used are [‘block1_conv1’, ‘block1_conv2’, ‘block2_conv1’,
‘block2_conv2’, ‘block3_conv1’, ‘block3_conv2’, ‘block3_conv3’,
‘block3_conv4’, ‘block4_conv1’, ‘block4_conv2’, ‘block4_conv3’,
‘block4_conv4’, ‘block5_conv1’, ‘block5_conv2’, ‘block5_conv3’,
‘block5_conv4’].  This is a proposed improvement from
<a class="reference external" href="https://arxiv.org/abs/1605.04603">https://arxiv.org/abs/1605.04603</a>.  In the original implementation, the
layers used are: [‘block1_conv1’, ‘block2_conv1’, ‘block3_conv1’,</p>
<blockquote>
<div><p>’block4_conv1’, ‘block5_conv1’].</p>
</div></blockquote>
</p></li>
<li><p><strong>content_mask</strong> (<em>ANTsImage</em>) – Specify the region for content consideration.</p></li>
<li><p><strong>style_masks</strong> (<em>ANTsImage</em><em> or </em><em>list of ANTsImages</em>) – Specify the region for style consideration.</p></li>
<li><p><strong>use_shifted_activations</strong> (<em>boolean</em>) – Use shifted activations in calculating the Gram matrix (improvement
mentioned in <a class="reference external" href="https://arxiv.org/abs/1605.04603">https://arxiv.org/abs/1605.04603</a>).</p></li>
<li><p><strong>use_chained_inference</strong> (<em>boolean</em>) – Another proposed improvement from <a class="reference external" href="https://arxiv.org/abs/1605.04603">https://arxiv.org/abs/1605.04603</a>.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
<li><p><strong>output_prefix</strong> (<em>string</em>) – If specified, outputs a png image to disk at each iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ANTs 3-component image.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">neural_style_transfer</span><span class="p">(</span><span class="n">content_image</span><span class="p">,</span> <span class="n">style_image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.el_bicho">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">el_bicho</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ventilation_image</span></em>, <em class="sig-param"><span class="n">mask</span></em>, <em class="sig-param"><span class="n">use_coarse_slices_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/lung_segmentation.html#el_bicho"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.el_bicho" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform functional lung segmentation using hyperpolarized gases.</p>
<p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/30195415/">https://pubmed.ncbi.nlm.nih.gov/30195415/</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ventilation_image</strong> (<em>ANTsImage</em>) – input ventilation image.</p></li>
<li><p><strong>mask</strong> (<em>ANTsImage</em>) – input mask.</p></li>
<li><p><strong>use_coarse_slices_only</strong> (<em>boolean</em>) – If True, apply network only in the dimension of greatest slice thickness.
If False, apply to all dimensions and average the results.</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Ventilation segmentation and corresponding probability images</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;ventilation.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="s2">&quot;mask.nii.gz&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lung_seg</span> <span class="o">=</span> <span class="n">el_bicho</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">use_coarse_slices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.arterial_lesion_segmentation">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">arterial_lesion_segmentation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/histology.html#arterial_lesion_segmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.arterial_lesion_segmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform arterial lesion segmentation using U-net.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – input image</p></li>
<li><p><strong>antsxnet_cache_directory</strong> (<em>string</em>) – Destination directory for storing the downloaded template and model weights.
Since these can be resused, if is None, these data will be downloaded to a
~/.keras/ANTsXNet/.</p></li>
<li><p><strong>verbose</strong> (<em>boolean</em>) – Print progress to the screen.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dictionary of ANTs segmentation and probability images.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">arterial_lesion_segmentation</span><span class="p">(</span><span class="n">histology_image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="miscellaneous">
<h2>Miscellaneous<a class="headerlink" href="#miscellaneous" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="antspynet.utilities.get_pretrained_network">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">get_pretrained_network</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">file_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">target_file_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/get_pretrained_network.html#get_pretrained_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.get_pretrained_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Download pretrained network/weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>string</strong> (<em>antsxnet_cache_directory</em>) – One of the permitted file ids or pass “show” to list all
valid possibilities. Note that most require internet access
to download.</p></li>
<li><p><strong>string</strong> – Optional target filename.</p></li>
<li><p><strong>string</strong> – Optional target output.  If not specified these data will be downloaded
to the subdirectory ~/.keras/ANTsXNet/.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A filename string</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model_file</span> <span class="o">=</span> <span class="n">get_pretrained_network</span><span class="p">(</span><span class="s1">&#39;dbpn4x&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.get_antsxnet_data">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">get_antsxnet_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">file_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">target_file_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">antsxnet_cache_directory</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/get_antsxnet_data.html#get_antsxnet_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.get_antsxnet_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Download data such as prefabricated templates and spatial priors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>string</strong> (<em>antsxnet_cache_directory</em>) – One of the permitted file ids or pass “show” to list all
valid possibilities. Note that most require internet access
to download.</p></li>
<li><p><strong>string</strong> – Optional target filename.</p></li>
<li><p><strong>string</strong> – Optional target output.  If not specified these data will be downloaded
to the subdirectory ~/.keras/ANTsXNet/.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A filename string</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">template_file</span> <span class="o">=</span> <span class="n">get_antsxnet_data</span><span class="p">(</span><span class="s1">&#39;biobank&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt id="antspynet.utilities.Scale">
<em class="property">class </em><code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">Scale</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/denseunet_utilities.html#Scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.Scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Custom layer used in the Dense U-net class for normalization which
learns a set of weights and biases for scaling the input data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>integer</em>) – Specifies which axis to normalize.</p></li>
<li><p><strong>momentum</strong> (<em>scalar</em>) – Value used for computation of the exponential average of the
mean and standard deviation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.regression_match_image">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">regression_match_image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">source_image</span></em>, <em class="sig-param"><span class="n">reference_image</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">poly_order</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">truncate</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/regression_match_image.html#regression_match_image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.regression_match_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Image intensity normalization using linear regression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_image</strong> (<em>ANTsImage</em>) – Image whose intensities are matched to the reference
image.</p></li>
<li><p><strong>reference_image</strong> (<em>ANTsImage</em>) – Defines the reference intensity function.</p></li>
<li><p><strong>poly_order</strong> (<em>integer</em>) – Polynomial order of fit.  Default is 1 (linear fit).</p></li>
<li><p><strong>mask</strong> (<em>ANTsImage</em>) – Defines voxels for regression modeling.</p></li>
<li><p><strong>truncate</strong> (<em>boolean</em>) – Turns on/off the clipping of intensities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ANTs image (i.e., source_image) matched to the (reference_image)</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">source_image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference_image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r64&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matched_image</span> <span class="o">=</span> <span class="n">regression_match_image</span><span class="p">(</span><span class="n">source_image</span><span class="p">,</span> <span class="n">reference_image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.randomly_transform_image_data">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">randomly_transform_image_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">reference_image</span></em>, <em class="sig-param"><span class="n">input_image_list</span></em>, <em class="sig-param"><span class="n">segmentation_image_list</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">number_of_simulations</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">transform_type</span><span class="o">=</span><span class="default_value">'affine'</span></em>, <em class="sig-param"><span class="n">sd_affine</span><span class="o">=</span><span class="default_value">0.02</span></em>, <em class="sig-param"><span class="n">deformation_transform_type</span><span class="o">=</span><span class="default_value">'bspline'</span></em>, <em class="sig-param"><span class="n">number_of_random_points</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">sd_noise</span><span class="o">=</span><span class="default_value">10.0</span></em>, <em class="sig-param"><span class="n">number_of_fitting_levels</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">mesh_size</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">sd_smoothing</span><span class="o">=</span><span class="default_value">4.0</span></em>, <em class="sig-param"><span class="n">input_image_interpolator</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">segmentation_image_interpolator</span><span class="o">=</span><span class="default_value">'nearestNeighbor'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/randomly_transform_image_data.html#randomly_transform_image_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.randomly_transform_image_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly transform image data (optional: with corresponding segmentations).</p>
<p>Apply rigid, affine and/or deformable maps to an input set of training
images.  The reference image domain defines the space in which this
happens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reference_image</strong> (<em>ANTsImage</em>) – Defines the spatial domain for all output images.  If the input images do
not match the spatial domain of the reference image, we internally
resample the target to the reference image.  This could have unexpected
consequences.  Resampling to the reference domain is performed by testing
using ants.image_physical_space_consistency then calling
ants.resample_image_to_target with failure.</p></li>
<li><p><strong>input_image_list</strong> (<em>list of lists of ANTsImages</em>) – List of lists of input images to warp.  The internal list sets contain one
or more images (per subject) which are assumed to be mutually aligned.  The
outer list contains multiple subject lists which are randomly sampled to
produce output image list.</p></li>
<li><p><strong>segmentation_image_list</strong> (<em>list of ANTsImages</em>) – List of segmentation images corresponding to the input image list (optional).</p></li>
<li><p><strong>number_of_simulations</strong> (<em>integer</em>) – Number of simulated output image sets.</p></li>
<li><p><strong>transform_type</strong> (<em>string</em>) – One of the following options: “translation”, “rigid”, “scaleShear”, “affine”,
“deformation”, “affineAndDeformation”.</p></li>
<li><p><strong>sd_affine</strong> (<em>float</em>) – Parameter dictating deviation amount from identity for random linear
transformations.</p></li>
<li><p><strong>deformation_transform_type</strong> (<em>string</em>) – “bspline” or “exponential”.</p></li>
<li><p><strong>number_of_random_points</strong> (<em>integer</em>) – Number of displacement points for the deformation field.</p></li>
<li><p><strong>sd_noise</strong> (<em>float</em>) – Standard deviation of the displacement field.</p></li>
<li><p><strong>number_of_fitting_levels</strong> (<em>integer</em>) – Number of fitting levels (bspline deformation only).</p></li>
<li><p><strong>mesh_size</strong> (<em>int</em><em> or </em><em>n-D tuple</em>) – Determines fitting resolution (bspline deformation only).</p></li>
<li><p><strong>sd_smoothing</strong> (<em>float</em>) – Standard deviation of the Gaussian smoothing in mm (exponential field only).</p></li>
<li><p><strong>input_image_interpolator</strong> (<em>string</em>) – One of the following options: “nearestNeighbor”, “linear”, “gaussian”, “bSpline”.</p></li>
<li><p><strong>segmentation_image_interpolator</strong> (<em>string</em>) – Only “nearestNeighbor” is currently available.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of lists of transformed images</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image1_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_segmentations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_segmentations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">threshold_image</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span> <span class="s2">&quot;Otsu&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_segmentations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">threshold_image</span><span class="p">(</span><span class="n">image2</span><span class="p">,</span> <span class="s2">&quot;Otsu&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_images</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image1_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image2_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">antspynet</span><span class="o">.</span><span class="n">randomly_transform_image_data</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">input_images</span><span class="p">,</span> <span class="n">input_segmentations</span><span class="p">,</span> <span class="n">sd_affine</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">transform_type</span> <span class="o">=</span> <span class="s2">&quot;affineAndDeformation&quot;</span> <span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.data_augmentation">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">data_augmentation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_image_list</span></em>, <em class="sig-param"><span class="n">segmentation_image_list</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">number_of_simulations</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">reference_image</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">transform_type</span><span class="o">=</span><span class="default_value">'affineAndDeformation'</span></em>, <em class="sig-param"><span class="n">noise_model</span><span class="o">=</span><span class="default_value">'additivegaussian'</span></em>, <em class="sig-param"><span class="n">noise_parameters</span><span class="o">=</span><span class="default_value">0.0, 0.05</span></em>, <em class="sig-param"><span class="n">sd_simulated_bias_field</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">sd_histogram_warping</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">output_numpy_file_prefix</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/data_augmentation.html#data_augmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.data_augmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly transform image data.</p>
<p>Given an input image list (possibly multi-modal) and an optional corresponding
segmentation image list, this function will perform data augmentation with
the following augmentation possibilities:</p>
<ul class="simple">
<li><p>spatial transformations</p></li>
<li><p>added image noise</p></li>
<li><p>simulated bias field</p></li>
<li><p>histogram warping</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_image_list</strong> (<em>list of lists of ANTsImages</em>) – List of lists of input images to warp.  The internal list sets contain one
or more images (per subject) which are assumed to be mutually aligned.  The
outer list contains multiple subject lists which are randomly sampled to
produce output image list.</p></li>
<li><p><strong>segmentation_image_list</strong> (<em>list of ANTsImages</em>) – List of segmentation images corresponding to the input image list (optional).</p></li>
<li><p><strong>number_of_simulations</strong> (<em>integer</em>) – Number of simulated output image sets.</p></li>
<li><p><strong>reference_image</strong> (<em>ANTsImage</em>) – Defines the spatial domain for all output images.  If one is not specified,
we used the first image in the input image list.</p></li>
<li><p><strong>transform_type</strong> (<em>string</em>) – One of the following options: “translation”, “rigid”, “scaleShear”, “affine”,
“deformation”, “affineAndDeformation”.</p></li>
<li><p><strong>noise_model</strong> (<em>string</em>) – ‘additivegaussian’, ‘saltandpepper’, ‘shot’, or ‘speckle’.</p></li>
<li><p><strong>noise_parameters</strong> (<em>tuple</em><em> or </em><em>array</em><em> or </em><em>float</em>) – ‘additivegaussian’: (mean, standardDeviation)
‘saltandpepper’: (probability, saltValue, pepperValue)
‘shot’: scale
‘speckle’: standardDeviation
Note that the standard deviation, scale, and probability values are <em>max</em> values
and are randomly selected in the range [0, noise_parameter].  Also, the “mean”,
“saltValue” and “pepperValue” are assumed to be in the intensity normalized range
of [0, 1].</p></li>
<li><p><strong>sd_simulated_bias_field</strong> (<em>float</em>) – Characterize the standard deviation of the amplitude.</p></li>
<li><p><strong>sd_histogram_warping</strong> (<em>float</em>) – Determines the strength of the bias field.</p></li>
<li><p><strong>output_numpy_file_prefix</strong> (<em>string</em>) – Filename of output numpy array containing all the simulated images and segmentations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of lists of transformed images and/or outputs to a numpy array.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image1_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r16&quot;</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image2_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_segmentations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_segmentations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">threshold_image</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span> <span class="s2">&quot;Otsu&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_segmentations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">threshold_image</span><span class="p">(</span><span class="n">image2</span><span class="p">,</span> <span class="s2">&quot;Otsu&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_images</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image1_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image2_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">antspynet</span><span class="o">.</span><span class="n">data_augmentation</span><span class="p">(</span><span class="n">input_images</span><span class="p">,</span>
<span class="go">                                       input_segmentations)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.histogram_warp_image_intensities">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">histogram_warp_image_intensities</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">break_points</span><span class="o">=</span><span class="default_value">0.25, 0.5, 0.75</span></em>, <em class="sig-param"><span class="n">displacements</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">clamp_end_points</span><span class="o">=</span><span class="default_value">False, False</span></em>, <em class="sig-param"><span class="n">sd_displacements</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">transform_domain_size</span><span class="o">=</span><span class="default_value">20</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/histogram_warp_image_intensities.html#histogram_warp_image_intensities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.histogram_warp_image_intensities" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform image intensities based on histogram mapping.</p>
<p>Apply B-spline 1-D maps to an input image for intensity warping.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – Input image.</p></li>
<li><p><strong>break_points</strong> (<em>integer</em><em> or </em><em>tuple</em>) – Parametric points at which the intensity transform displacements
are specified between [0, 1].  Alternatively, a single number can
be given and the sequence is linearly spaced in [0, 1].</p></li>
<li><p><strong>displacements</strong> (<em>tuple</em>) – displacements to define intensity warping.  Length must be equal to the
breakPoints.  Alternatively, if None random displacements are chosen
(random normal:  mean = 0, sd = sd_displacements).</p></li>
<li><p><strong>sd_displacements</strong> (<em>float</em>) – Characterize the randomness of the intensity displacement.</p></li>
<li><p><strong>clamp_end_points</strong> (<em>2-element tuple of booleans</em>) – Specify non-zero intensity change at the ends of the histogram.</p></li>
<li><p><strong>transform_domain_size</strong> (<em>integer</em>) – Defines the sampling resolution of the B-spline warping.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ANTs image</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformed_image</span> <span class="o">=</span> <span class="n">histogram_warp_image_intensities</span><span class="p">(</span> <span class="n">image</span> <span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.simulate_bias_field">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">simulate_bias_field</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">domain_image</span></em>, <em class="sig-param"><span class="n">number_of_points</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">sd_bias_field</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">number_of_fitting_levels</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">mesh_size</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/simulate_bias_field.html#simulate_bias_field"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.simulate_bias_field" title="Permalink to this definition">¶</a></dt>
<dd><p>Simulate random bias field</p>
<p>Low frequency, spatial varying simulated random bias field using
random points and B-spline fitting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>domain_image</strong> (<em>ANTsImage</em>) – Image to define the spatial domain of the bias field.</p></li>
<li><p><strong>number_of_points</strong> (<em>integer</em>) – Number of randomly defined points to define the bias field
(default = 10).</p></li>
<li><p><strong>sd_bias_field</strong> (<em>float</em>) – Characterize the standard deviation of the amplitude (default = 1).</p></li>
<li><p><strong>number_of_fitting_levels</strong> (<em>integer</em>) – B-spline fitting parameter.</p></li>
<li><p><strong>clamp_end_points</strong> (<em>integer</em><em> or </em><em>tuple</em>) – B-spline fitting parameter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ANTs image</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s2">&quot;r64&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bias_field_image</span> <span class="o">=</span> <span class="n">simulate_bias_field</span><span class="p">(</span> <span class="n">image</span> <span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.crop_image_center">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">crop_image_center</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">crop_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/cropping_and_padding_utilities.html#crop_image_center"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.crop_image_center" title="Permalink to this definition">¶</a></dt>
<dd><p>Crop the center of an image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – Input image</p></li>
<li><p><strong>crop_size</strong> (<em>n-D tuple</em><em> (</em><em>depending on dimensionality</em><em>)</em><em></em>) – Width, height, depth (if 3-D), and time (if 4-D) of crop region.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A list (or array) of patches.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cropped_image</span> <span class="o">=</span> <span class="n">crop_image_center</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">crop_size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.pad_or_crop_image_to_size">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">pad_or_crop_image_to_size</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/cropping_and_padding_utilities.html#pad_or_crop_image_to_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.pad_or_crop_image_to_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad or crop an image to a specified size</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – Input image</p></li>
<li><p><strong>size</strong> (<em>tuple</em>) – size of output image</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A cropped or padded image</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">padded_image</span> <span class="o">=</span> <span class="n">pad_or_crop_image_to_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">333</span><span class="p">,</span> <span class="mi">333</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.pad_image_by_factor">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">pad_image_by_factor</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">image</span></em>, <em class="sig-param"><span class="n">factor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/cropping_and_padding_utilities.html#pad_image_by_factor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.pad_image_by_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad an image based on a factor.</p>
<p>Pad image of size (x, y, z) to (x’, y’, z’) where (x’, y’, z’)
is a divisible by a user-specified factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>ANTsImage</em>) – Input image</p></li>
<li><p><strong>factor</strong> (<em>scalar</em><em> or </em><em>n-D tuple</em>) – Padding factor</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A padded image</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">padded_image</span> <span class="o">=</span> <span class="n">pad_image_by_factor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.encode_unet">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">encode_unet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">segmentations_array</span></em>, <em class="sig-param"><span class="n">segmentation_labels</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/unet_utilities.html#encode_unet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.encode_unet" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic one-hot transformation of segmentations array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>segmentations_array</strong> (<em>numpy array</em>) – multi-label numpy array</p></li>
<li><p><strong>segmentation_labels</strong> (<em>tuple</em><em> or </em><em>list</em>) – Note that a background label (typically 0) needs to be included.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>An n-d array of shape batch_size x width x height x &lt;depth&gt; x number_of_segmentation_labels</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seg</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">kmeans_segmentation</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">3</span><span class="p">)[</span><span class="s1">&#39;segmentation&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">one_hot</span> <span class="o">=</span> <span class="n">encode_unet</span><span class="p">(</span><span class="n">seg</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="antspynet.utilities.decode_unet">
<code class="sig-prename descclassname">antspynet.utilities.</code><code class="sig-name descname">decode_unet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_predicted</span></em>, <em class="sig-param"><span class="n">domain_image</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/antspynet/utilities/unet_utilities.html#decode_unet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#antspynet.utilities.decode_unet" title="Permalink to this definition">¶</a></dt>
<dd><p>Decoding function for the u-net prediction outcome</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_predicted</strong> (<em>an array</em>) – Shape batch_size x width x height x &lt;depth&gt; x number_of_segmentation_labels</p></li>
<li><p><strong>domain_image</strong> (<em>ANTs image</em>) – Defines the geometry of the returned probability images</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List of probability images.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ants</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ants</span><span class="o">.</span><span class="n">image_read</span><span class="p">(</span><span class="n">ants</span><span class="o">.</span><span class="n">get_ants_data</span><span class="p">(</span><span class="s1">&#39;r16&#39;</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">ANTsPyNet</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architectures.html">Architectures</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#custom-metrics">Custom metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-normalization-layers">Custom normalization layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-activation-layers">Custom activation layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#resample-tensor-layer">Resample tensor layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mixture-density-networks">Mixture density networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#attention">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clustering">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="#image-patch">Image patch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#super-resolution">Super-resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#spatial-transformer-network">Spatial transformer network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#applications">Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="#miscellaneous">Miscellaneous</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="architectures.html" title="previous chapter">Architectures</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Nick Tustison, Nick Cullen, Brian Avants.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/utilities.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>